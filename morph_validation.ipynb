{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"morph_validation.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"7PEbVxXZiV-i","colab_type":"code","colab":{},"outputId":"99372ed2-9b27-4965-d637-a68a5478f500"},"source":["import SimpleITK as sitk  # For loading the dataset\n","import numpy as np  # For data manipulation\n","from model import build_model  # For creating the model\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from scipy.ndimage import zoom\n","import cv2\n","import keras.backend as K\n","from keras.utils import Sequence\n","from keras.callbacks.callbacks import LambdaCallback\n","import cv2"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"rOQqCHRziV-p","colab_type":"code","colab":{}},"source":["def read_img(img_path):\n","    \"\"\"\n","    Reads a .nii.gz image and returns as a numpy array.\n","    \"\"\"\n","    return sitk.GetArrayFromImage(sitk.ReadImage(img_path))\n","\n","\n","def resize(img, shape, mode='constant', orig_shape=(155, 240, 240)):\n","    \"\"\"\n","    Wrapper for scipy.ndimage.zoom suited for MRI images.\n","    \"\"\"\n","    assert len(shape) == 3, \"Can not have more than 3 dimensions\"\n","    factors = (\n","        shape[0]/orig_shape[0],\n","        shape[1]/orig_shape[1], \n","        shape[2]/orig_shape[2]\n","    )\n","    \n","    # Resize to the given shape\n","    return zoom(img, factors, mode=mode)\n","\n","\n","def preprocess(img, out_shape=None):\n","    \"\"\"\n","    Preprocess the image.\n","    Just an example, you can add more preprocessing steps if you wish to.\n","    \"\"\"\n","    if out_shape is not None:\n","        img = resize(img, out_shape, mode='constant')\n","    \n","    # Normalize the image\n","    mean = img.mean()\n","    std = img.std()\n","    return (img - mean) / std\n","\n","\n","def preprocess_label(img, out_shape=None, mode='nearest'):\n","    \"\"\"\n","    Separates out the 3 labels from the segmentation provided, namely:\n","    GD-enhancing tumor (ET ? label 4), the peritumoral edema (ED ? label 2))\n","    and the necrotic and non-enhancing tumor core (NCR/NET ? label 1)\n","    \"\"\"\n","    # print(img.shape)\n","    # print(np.unique(img))\n","    ncr = img == 1  # Necrotic and Non-Enhancing Tumor (NCR/NET)\n","    ed = img == 2  # Peritumoral Edema (ED)\n","    et = img == 4  # GD-enhancing Tumor (ET)\n","    \n","    if out_shape is not None:\n","        ncr = resize(ncr, out_shape, mode=mode)\n","        ed = resize(ed, out_shape, mode=mode)\n","        et = resize(et, out_shape, mode=mode)\n","\n","    return np.array([ncr, ed, et], dtype=np.uint8)\n","\n","def dice_coefficient(y_true, y_pred):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(K.abs(y_true_f * y_pred_f), axis=-1)\n","    return (2. * intersection) / (\n","        K.sum(K.square(y_true_f), -1) + K.sum(K.square(y_pred_f), -1) + 1e-8)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"L8VOCzVWiV-t","colab_type":"code","colab":{},"outputId":"9f0776aa-78fd-4960-a1ca-591417ecd5b8"},"source":["input_shape = (4, 96, 112, 112)\n","output_channels = 3\n","model = build_model(input_shape=input_shape, output_channels=3)\n","model.load_weights('weights/weights.epoch_100-loss_-0.14610-dice_0.64230-val_dice_0.58464.hdf5')\n","\n","#validation samples\n","samples=[{'t1': 'HGG/Brats18_TCIA01_460_1/Brats18_TCIA01_460_1_t1.nii.gz', 't2': 'HGG/Brats18_TCIA01_460_1/Brats18_TCIA01_460_1_t2.nii.gz', 't1ce': 'HGG/Brats18_TCIA01_460_1/Brats18_TCIA01_460_1_t1ce.nii.gz', 'flair': 'HGG/Brats18_TCIA01_460_1/Brats18_TCIA01_460_1_flair.nii.gz', 'seg': 'HGG/Brats18_TCIA01_460_1/Brats18_TCIA01_460_1_seg.nii.gz'}, {'t1': 'HGG/Brats18_CBICA_AMH_1/Brats18_CBICA_AMH_1_t1.nii.gz', 't2': 'HGG/Brats18_CBICA_AMH_1/Brats18_CBICA_AMH_1_t2.nii.gz', 't1ce': 'HGG/Brats18_CBICA_AMH_1/Brats18_CBICA_AMH_1_t1ce.nii.gz', 'flair': 'HGG/Brats18_CBICA_AMH_1/Brats18_CBICA_AMH_1_flair.nii.gz', 'seg': 'HGG/Brats18_CBICA_AMH_1/Brats18_CBICA_AMH_1_seg.nii.gz'}, {'t1': 'HGG/Brats18_CBICA_ASV_1/Brats18_CBICA_ASV_1_t1.nii.gz', 't2': 'HGG/Brats18_CBICA_ASV_1/Brats18_CBICA_ASV_1_t2.nii.gz', 't1ce': 'HGG/Brats18_CBICA_ASV_1/Brats18_CBICA_ASV_1_t1ce.nii.gz', 'flair': 'HGG/Brats18_CBICA_ASV_1/Brats18_CBICA_ASV_1_flair.nii.gz', 'seg': 'HGG/Brats18_CBICA_ASV_1/Brats18_CBICA_ASV_1_seg.nii.gz'}, {'t1': 'HGG/Brats18_TCIA02_377_1/Brats18_TCIA02_377_1_t1.nii.gz', 't2': 'HGG/Brats18_TCIA02_377_1/Brats18_TCIA02_377_1_t2.nii.gz', 't1ce': 'HGG/Brats18_TCIA02_377_1/Brats18_TCIA02_377_1_t1ce.nii.gz', 'flair': 'HGG/Brats18_TCIA02_377_1/Brats18_TCIA02_377_1_flair.nii.gz', 'seg': 'HGG/Brats18_TCIA02_377_1/Brats18_TCIA02_377_1_seg.nii.gz'}, {'t1': 'HGG/Brats18_CBICA_ATD_1/Brats18_CBICA_ATD_1_t1.nii.gz', 't2': 'HGG/Brats18_CBICA_ATD_1/Brats18_CBICA_ATD_1_t2.nii.gz', 't1ce': 'HGG/Brats18_CBICA_ATD_1/Brats18_CBICA_ATD_1_t1ce.nii.gz', 'flair': 'HGG/Brats18_CBICA_ATD_1/Brats18_CBICA_ATD_1_flair.nii.gz', 'seg': 'HGG/Brats18_CBICA_ATD_1/Brats18_CBICA_ATD_1_seg.nii.gz'}, {'t1': 'HGG/Brats18_TCIA02_374_1/Brats18_TCIA02_374_1_t1.nii.gz', 't2': 'HGG/Brats18_TCIA02_374_1/Brats18_TCIA02_374_1_t2.nii.gz', 't1ce': 'HGG/Brats18_TCIA02_374_1/Brats18_TCIA02_374_1_t1ce.nii.gz', 'flair': 'HGG/Brats18_TCIA02_374_1/Brats18_TCIA02_374_1_flair.nii.gz', 'seg': 'HGG/Brats18_TCIA02_374_1/Brats18_TCIA02_374_1_seg.nii.gz'}, {'t1': 'HGG/Brats18_TCIA03_133_1/Brats18_TCIA03_133_1_t1.nii.gz', 't2': 'HGG/Brats18_TCIA03_133_1/Brats18_TCIA03_133_1_t2.nii.gz', 't1ce': 'HGG/Brats18_TCIA03_133_1/Brats18_TCIA03_133_1_t1ce.nii.gz', 'flair': 'HGG/Brats18_TCIA03_133_1/Brats18_TCIA03_133_1_flair.nii.gz', 'seg': 'HGG/Brats18_TCIA03_133_1/Brats18_TCIA03_133_1_seg.nii.gz'}, {'t1': 'HGG/Brats18_TCIA03_265_1/Brats18_TCIA03_265_1_t1.nii.gz', 't2': 'HGG/Brats18_TCIA03_265_1/Brats18_TCIA03_265_1_t2.nii.gz', 't1ce': 'HGG/Brats18_TCIA03_265_1/Brats18_TCIA03_265_1_t1ce.nii.gz', 'flair': 'HGG/Brats18_TCIA03_265_1/Brats18_TCIA03_265_1_flair.nii.gz', 'seg': 'HGG/Brats18_TCIA03_265_1/Brats18_TCIA03_265_1_seg.nii.gz'}, {'t1': 'HGG/Brats18_TCIA02_394_1/Brats18_TCIA02_394_1_t1.nii.gz', 't2': 'HGG/Brats18_TCIA02_394_1/Brats18_TCIA02_394_1_t2.nii.gz', 't1ce': 'HGG/Brats18_TCIA02_394_1/Brats18_TCIA02_394_1_t1ce.nii.gz', 'flair': 'HGG/Brats18_TCIA02_394_1/Brats18_TCIA02_394_1_flair.nii.gz', 'seg': 'HGG/Brats18_TCIA02_394_1/Brats18_TCIA02_394_1_seg.nii.gz'}, {'t1': 'HGG/Brats18_2013_21_1/Brats18_2013_21_1_t1.nii.gz', 't2': 'HGG/Brats18_2013_21_1/Brats18_2013_21_1_t2.nii.gz', 't1ce': 'HGG/Brats18_2013_21_1/Brats18_2013_21_1_t1ce.nii.gz', 'flair': 'HGG/Brats18_2013_21_1/Brats18_2013_21_1_flair.nii.gz', 'seg': 'HGG/Brats18_2013_21_1/Brats18_2013_21_1_seg.nii.gz'}]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0305 14:48:10.878890 140453689906944 deprecation.py:506] From /usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"gpBuUAYaiV-x","colab_type":"code","colab":{},"outputId":"5dc95241-1f99-4cd3-b1d7-580ef25768f2"},"source":["kernel = np.ones((3, 3))\n","File = []\n","Binary = []\n","Gray = []\n","Processed_Binary = []\n","Processed_Gray = []\n","\n","for i in samples:\n","    File.append(i['t1'].split('/')[1])\n","    print(\"File: %s\"%File[-1])\n","    \n","    data_x = np.empty((1,) + input_shape, dtype=np.float32)\n","    labels = np.empty((1, output_channels) + input_shape[1:], dtype=np.uint8)\n","    \n","    data_x[0] = np.array([preprocess(read_img(i[m]), input_shape[1:]) for m in ['t1', 't2', 't1ce', 'flair']], dtype=np.float32)\n","    labels[0] = preprocess_label(read_img(i['seg']), input_shape[1:])[None, ...]\n","    \n","    preds = model.predict(data_x)[0]\n","    \n","    pbinary = [] #predicted binary\n","    pgray = [] #predicted grayscale\n","    label_gray = [] #original gray\n","    label_binary = [] #original binary\n","\n","    binary = [] #processed binary\n","    gray = [] #processed grayscale\n","    original_gray = [] #processed original gray\n","    original_binary = [] #processed original binary\n","    for i in range(96):\n","        pred = preds[:, i,:,:]\n","        pred = np.transpose(pred, (1, 2, 0))\n","        pred = np.rint(pred)\n","        pred = pred*255\n","        pred_gray = cv2.cvtColor(pred, cv2.COLOR_BGR2GRAY)\n","        pred_gray = pred_gray.astype(np.uint8)\n","        pgray.append(pred_gray)\n","        pbinary.append(np.array(pred_gray>0).astype(int))\n","        pred_gray_closed = cv2.morphologyEx(pred_gray, cv2.MORPH_CLOSE, kernel, iterations=3)\n","        gray.append(pred_gray_closed)\n","        pred_binary = np.array(pred_gray_closed>0).astype(int)\n","        binary.append(pred_binary)\n","        orig = labels[0][:, i,:,:]\n","        orig = np.transpose(orig, (1, 2, 0))\n","        orig = orig*255\n","        orig_gray = cv2.cvtColor(orig, cv2.COLOR_BGR2GRAY)\n","        orig_gray = orig_gray.astype(np.uint8)\n","        label_gray.append(orig_gray)\n","        label_binary.append(np.array(orig_gray>0).astype(int))\n","        orig_gray_closed = cv2.morphologyEx(orig_gray, cv2.MORPH_CLOSE, kernel, iterations=3)\n","        original_gray.append(orig_gray_closed)\n","        orig_binary = np.array(orig_gray_closed>0).astype(int)\n","        original_binary.append(orig_binary)\n","        \n","    Binary.append(K.get_value(dice_coefficient(K.constant(np.array(label_binary)), K.constant(np.array(pbinary)))))\n","    Gray.append(K.get_value(dice_coefficient(K.constant(np.array(label_gray)), K.constant(np.array(pgray)))))\n","    Processed_Binary.append(K.get_value(dice_coefficient(K.constant(np.array(original_binary)), K.constant(np.array(binary)))))\n","    Processed_Gray.append(K.get_value(dice_coefficient(K.constant(np.array(original_gray)), K.constant(np.array(gray)))))\n","    print(\"Dice score without post processing for binary: %s\"%Binary[-1])\n","    print(\"Dice score without post processing for gray: %s\"%Gray[-1])\n","    print(\"Dice score with post processing for binary: %s\"%Processed_Binary[-1])\n","    print(\"Dice score with post processing for gray: %s\\n\"%Processed_Gray[-1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["File: Brats18_TCIA01_460_1\n"],"name":"stdout"},{"output_type":"stream","text":["W0305 14:48:19.806359 140453689906944 module_wrapper.py:139] From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Dice score without processing for binary: 0.5420551\n","Dice score without processing for gray: 0.44221228\n","Dice score without processing for processed binary: 0.8815477\n","Dice score without processing for processed gray: 0.67411387\n","\n","File: Brats18_CBICA_AMH_1\n","Dice score without processing for binary: 0.60972184\n","Dice score without processing for gray: 0.6168306\n","Dice score without processing for processed binary: 0.92466986\n","Dice score without processing for processed gray: 0.9132088\n","\n","File: Brats18_CBICA_ASV_1\n","Dice score without processing for binary: 0.611202\n","Dice score without processing for gray: 0.61653197\n","Dice score without processing for processed binary: 0.9433235\n","Dice score without processing for processed gray: 0.9377231\n","\n","File: Brats18_TCIA02_377_1\n","Dice score without processing for binary: 0.6236397\n","Dice score without processing for gray: 0.6269005\n","Dice score without processing for processed binary: 0.9460473\n","Dice score without processing for processed gray: 0.9392112\n","\n","File: Brats18_CBICA_ATD_1\n","Dice score without processing for binary: 0.55790305\n","Dice score without processing for gray: 0.554228\n","Dice score without processing for processed binary: 0.9103645\n","Dice score without processing for processed gray: 0.8860441\n","\n","File: Brats18_TCIA02_374_1\n","Dice score without processing for binary: 0.5862654\n","Dice score without processing for gray: 0.5661444\n","Dice score without processing for processed binary: 0.926435\n","Dice score without processing for processed gray: 0.8798951\n","\n","File: Brats18_TCIA03_133_1\n","Dice score without processing for binary: 0.57626486\n","Dice score without processing for gray: 0.5557845\n","Dice score without processing for processed binary: 0.8741466\n","Dice score without processing for processed gray: 0.8486626\n","\n","File: Brats18_TCIA03_265_1\n","Dice score without processing for binary: 0.5606838\n","Dice score without processing for gray: 0.44851092\n","Dice score without processing for processed binary: 0.9063418\n","Dice score without processing for processed gray: 0.743053\n","\n","File: Brats18_TCIA02_394_1\n","Dice score without processing for binary: 0.5529412\n","Dice score without processing for gray: 0.57272273\n","Dice score without processing for processed binary: 0.8371598\n","Dice score without processing for processed gray: 0.8200722\n","\n","File: Brats18_2013_21_1\n","Dice score without processing for binary: 0.5547477\n","Dice score without processing for gray: 0.40789118\n","Dice score without processing for processed binary: 0.9209286\n","Dice score without processing for processed gray: 0.67182636\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"f6yfnS1ciV-1","colab_type":"code","colab":{}},"source":["df = pd.DataFrame({\n","    'File': File,\n","    'Binary': Binary,\n","    'Gray': Gray,\n","    'Processed_Binary': Processed_Binary,\n","    'Processed_Gray': Processed_Gray\n","})\n","df.to_csv('validation_accuracy.csv', index=False)"],"execution_count":0,"outputs":[]}]}